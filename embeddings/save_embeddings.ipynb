{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273e2a1-7e3b-4794-9073-a363757be1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A messy notebook for generating the embeddings from photos.'''\n",
    "\n",
    "import pandas as pd\n",
    "import torch \n",
    "\n",
    "from pathlib.Path import home\n",
    "from pytorch_lightning import Trainer\n",
    "from src.train import SphereClassifier, WhaleDataModule\n",
    "from config.config import load_config\n",
    "\n",
    "# config files - should reflect how the model was trained \n",
    "cfg = load_config('config/efficientnet_v2m.yaml', \"config/default.yaml\")\n",
    "\n",
    "# parent directory for input data\n",
    "INPUT_DIR = f'{home}/images_to_test'     \n",
    "\n",
    "# subdirectory with images\n",
    "image_dir = f\"{INPUT_DIR}/images\"                      \n",
    "\n",
    "# you'll need to have a dummy csv with one column \"images\" with the image file names\n",
    "LABEL_DF = pd.read_csv(f'{INPUT_DIR}/test_image_labels.csv') \n",
    "\n",
    "# parent directory for output data\n",
    "#   note that an output dir like this is created by training the model, e.g.,\n",
    "#   python -m src.train --config_path config/efficientnet_b6.yaml --exp_name b6\n",
    "OUT_DIR = \"../checkpoints/\" # 'result/v2m/-1' \n",
    "OUT_PATH = f'{OUT_DIR}/test_embeddings.npz' # name of output path \n",
    "\n",
    "# create data module\n",
    "data_module = WhaleDataModule(\n",
    "    LABEL_DF, \n",
    "    cfg, \n",
    "    image_dir=image_dir, \n",
    "    val_bbox_name=\"none\", # used if you need to add bounding boxes around animals, see src.dataset.load_bbox()\n",
    "    fold=-1               # -1 means use whole dataset\n",
    ")\n",
    "\n",
    "# build model and trainer \n",
    "model = SphereClassifier(cfg)\n",
    "\n",
    "trainer = Trainer(gpus=torch.cuda.device_count(), sync_batchnorm=True, precision=16)\n",
    "\n",
    "# load weights from checkpoint. if you trained model via src.train, should be a file like this in the OUT_DIR\n",
    "check_path = f'{OUT_DIR}/last.ckpt'\n",
    "model = model.load_from_checkpoint(check_path)\n",
    "\n",
    "# define output file path\n",
    "model.test_results_fp = OUT_PATH\n",
    "\n",
    "# build and save feature vectors \n",
    "trainer.test(model, data_module.all_dataloader())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
